\chapter{Grundlagen}
Für das Verständnis der Ausarbeitung werden einige Grundlagen benötigt.
In diesem Kapitel werden diese Grundlagen übermittelt.
Es werden die wichtigsten Eigenschaften des Serverless-Computing erläutert,
sowie gängige serverlose Dienste vorgestellt.

\section{Serverless-Computing}
Serverless-Computing ist ein Konzept, mit dem man skalierbare Anwendungen
entwickeln und ohne komplexe Serververwaltung bereitstellen kann \cite{CioGov}.
Das Konzept ist aktuell bei den öffentlichen Cloud-Providern beliebt, die viele
serverlose Dienste für Entwickler und Unternehmen bereitstellen. Trotz des Namens
werden selbstverständlich immer noch \textit{Server} verwendet. Der Name symbolisiert die geringe
und einfache Serververwaltung im Vergleich zur den üblichen selbstverwalteten
Diensten auf \cite{CNCF}.
Häufig wird der Begriff \textit{serverless} mit einer ganz bestimmten serverlosen Dienstart
assoziiert, den \textit{Function-as-a-Service} (FaaS).

Die Idee ist, dass Entwickler ihre Anwendungslogik aus isolierten und 
zustandslosen Funktionen aufbauen. Es ist vorgesehen, dass jede Funktion nur für eine
ganz spezifische Aufgabe zuständig ist. Die Funktionen können
durch Ereignisse (engl. \textit{Events}) ausgelöst werden. Treffen solche Ereignisse ein,
provisioniert der Cloudanbieter die passenden Ressourcen und führt die jeweilige Funktion aus.
Aufgrund des geringen Aufgabenbereichs und Zustandslosigkeit einer Funktion,
sind Cloudanbieter in der Lage sehr schnell mehrere Instanzen einer Funktion zu starten,
um eine erhöhte Nachfrage zu bewältigen.
Verringert sich die Nachfrage wieder, werden die Instanzen abgebaut. Anders ist 
es bei traditionellen selbstverwalteten Diensten. Dort müssen Entwickler die Nachfrage grob
abschätzen und bei zu hoher Nachfrage die Kapazitäten rechtzeitig
erhöhen \cite{WhatIsServerless} \cite{ServerlessTrends}.

Ein weiterer Vorteil des Serverless-Computing ist, dass Cloudanbieter
bei ihren serverlosen Diensten nur die eigentlichen Rechentätigkeiten
in Zahlung stellen, sodass für Entwickler und Unternehmen nur dann Kosten
anfallen, wenn ihre Anwendungen auch benutzt werden \cite{EcoArc}.

Auch das Wegfallen der Provisionierung und täglichen Verwaltung bringt Vorteile mit sich.
Entwickler können sich auf die eigentliche Entwicklung der Anwendungen konzentrieren und
müssen sich nicht mit den täglichen Kleinigkeiten des Entwicklungsalltags
beschäftigen \cite{ServerlessTrends}.

Somit lässt sich das Serverless-Computing Konzept gut auf Applikationen anwenden,
die über den Tag hinaus eine starke Schwankung in der Nachfrage haben. Der Cloudanbieter wird
die angefragten Funktionen passend hoch und runter skalieren. Auch wenn bereits stark auf 
andere Services eines Cloud-Providers zurückgegriffen wird, sind die serverlosen Dienste
gut für das Verknüpfen der Services geeignet. Da die einzelnen Funktionen durch Events
aktiviert werden, können Daten in eine Funktion eingeführt werden, um
dann an die benötigten Komponenten, in passendem Dateiformat, wieder ausgeführt zu werden
\cite{ServerlessTrends} \cite{HpcServerless}.

Um in den folgenden Kapiteln der Arbeit tiefer in die Architektur einer
serverlosen Platform und den Aspekt der Sicherheit eintauchen zu können,
werden die zwei Begriffe Virtual-Machine und Container vorgestellt.

\section{Virtual-Machine}
Bei einer Virtual-Machine handelt es sich um eine virtuelle Umgebung, mit 
eigenen virtuellen Ressourcen, wie unter anderem CPU und Speicher.
Ein \textit{Virtual Machine Monitor} (VMM), auch \textit{Hypervisor} genannt
ist ein Softwarestück, das dafür zuständig ist die 
virtuellen Umgebungen einschließlich seiner virtuellen Ressourcen zu verwalten
und Instruktionen auf die physischen Ressourcen abzubilden.
Der Hypervisor reserviert physische Ressourcen und plant die Zuweisen
an die einzelnen VMs. Er ist der Kommunikationskanal 
zwischen den virtuellen Umgebungen und der Hardware.
Ein großer Vorteil der Virtualisierung von Hardwareressourcen
ist, dass jede Virtual-Machine ihr eigenes Betriebssystem
benutzen kann. Somit können auf einer Maschine
mehrere Betriebssysteme laufen, die vollständig voneinander abgekapselt sind
\cite{RedHatVM} \cite{RedHatHypervisor}. Es wird unter zwei
Arten von Hypervisor unterschieden.

Ein nativer Hypervisor, auch \textit{Typ 1 Hypervisor} genannt, läuft direkt auf der physischen Hardware
und verwaltet die virtuellen Umgebungen und ihre Betriebssysteme. Ein gängiger Typ 1 Hypervisor ist
unter anderem Microsoft Hyper-V
\footnote{\url{https://docs.microsoft.com/de-de/virtualization/hyper-v-on-windows/}}
\cite{RedHatHypervisor}.
Ein hosted Hypervisor, auch \textit{Typ 2 Hypervisor}  genannt, läuft als übliche
Applikation auf dem Host-Betriebssystem. Beispiel hierfür wäre Oracle VirtualBox
\footnote{\url{https://www.virtualbox.org/}}, welches auch in der Informatik
an der Heinrich-Heine-Universität (HHU) verwendet wird \cite{HHUFachschaft}.
Der hosted Hypervisor kommuniziert mit dem Host-Betriebssystem und hat keinen direkten Zugriff auf die
physischen Ressourcen. Erst in Zusammenarbeit mit ihm
werden die Instruktionen an die physischen Hardwareressourcen weitergeleitet.
Somit laufen die virtuellen Umgebungen auf dem Host-Betriebssystem,
haben aber jeweils ein eigenes Betriebssystem \cite{RedHatHypervisor}.
Im Vergleich zu einem nativen Hypervisor ist das Erstellen einer VM
mit einem hosted Hypervisor ohne großen Aufwand möglich.
Ein Nachteil ist jedoch, dass sie langsamer und ineffizienter sind, da sie nicht
direkt mit der Hardware kommunizieren \cite{IBMHypervisor}.
Ein weiterer Hypervisor ist die Kernel-basierte Virtual Machine (KVM). KVM ist in
den Linux-Kernel \footnote{\url{https://www.kernel.org}} integriert und wandelt
das Linux-Betriebssystem in einen Typ 1 Hypervisor. Sie unterstützt
Hardware-Virtualisierungserweiterungen, wie beispielsweise Intel-VT
\footnote{\url{https://www.intel.de/content/www/de/de/virtualization/virtualization-technology/intel-virtualization-technology.html}}.
Diese Erweiterungen wurden eingeführt,
um die Virtualisierung zu beschleunigen und die Entwicklung
von Hypervisoren zu beschleunigen \cite{IBMHypervisor} \cite{RedHatKVM}.

\section{Container}
Virtualisierung ist auch mithilfe von Linux Container möglich,
was auch Containerisierung (engl. \textit{Containerization})
genannt wird. Diese enthalten isolierte Prozesse
\footnote{\url{https://www.tldp.org/LDP/tlk/kernel/processes.html}}.
Container teilen sich den Host-Kernel. Durch eine
Konfigurationsdatei (\textit{Image}) werden alle
nötigen Ressourcen und Dateien definiert, die für das Ausführen
der Prozesse benötigt werden. Dadurch spart man sich ein komplettes
Betriebsystem zu laden, wodurch sie den Vorteil,
dass sie kompakter und sparsamer sind. Entwickler steht eine eindeutig
definierte Laufzeitumgebung zur Verfügung, auf der sie ihre Anwendungen testen
können \cite{RedHatContainer}. Container bauen auf zwei Komponenten
des Linux-Kernels auf, den Namensräumen
(\textit{namespaces}) und den Kontrollgruppen
(\textit{cgroups}).

Mithilfe von namespaces stellt der Kernel eine Isolationsmöglichkeit
für Prozesse bereit. Mit ihnen können globale Ressourcen abstrahiert werden.
Prozesse innerhalb des namespaces sehen nur ihre isolierte lokale
Ausprägung der Ressource \cite{UbuntuNamespaces}.
Dadurch können mehrere Container gleichzeitig auf die gleiche
Ressource zugreifen \cite{RedHatIntroToLinuxContainers}.
Es existieren unterschiedliche namespaces, wie beispielsweise
\textit{mount namespaces} \footnote{\url{http://manpages.ubuntu.com/manpages/focal/man7/mount_namespaces.7.html}},
\textit{network namespaces} \footnote{\url{http://manpages.ubuntu.com/manpages/focal/man7/network_namespaces.7.html}}
und \textit{pid namespaces} \footnote{\url{http://manpages.ubuntu.com/manpages/focal/man7/pid_namespaces.7.html}}.
Durch mount namespaces kann die Sicht auf das Dateisystem
(engl. \textit{filesystem}) für Prozesse beschränkt werden.
Mit network namespaces lassen sich IP-Adressen, Ports
und Routing Tabellen isolieren. PID (deut. Prozess-ID) namespaces teilen
den Identifikationsbereich. Ein Prozess hat dadurch zwei
PIDs. Eine Identifaktionsnummer auf dem Host-Betriebssystem und eine
innerhalb des namespaces, welche sich beide unterscheiden können
\cite{lwnDotNetNamespaces}.

Cgroups haben zwei wichtige Aufgaben. Sie erlauben das Gruppieren
von Prozessen und können dynamisch Ressourcen für Gruppierungen begrenzen.
Begrenz werden können beispielsweise CPU Zeit und Speicher eines Prozesses
\cite{RedHatIntroToLinuxContainers}.


% \section{Function as a Service}
% -- Ein Cloud Computing Service wie PaaS, IaaS, SaaS\\
% -- Kleine, stateless Funktionen die einzelnd abgerechnet und skaliert werden\\

% \section{Serverless Containers}
% -- Laufzeitumgebung der serverlosen Anwendung wird durch Dockerimage bereitgestellt
% -- Anwendung kann beliebigen aufbau haben

% \section{Open-Source und self-hosted Lösungen}
% -- OpenFaaS
% -- IBM OpenWhisk
% -- Oracle Fn Project

% \section{Sichere Umgebungen}
% -- VMs sind zu Ressourcen intensiv
% -- Container sind nicht sicher

% \subsection{Google gVisor}
% -- Applikationskernel für Container in Golang\\
% -- Implementiert viele des Linux kernel interfaces\\
% -- Fängt SystemCalls ab und gibt sich als GuestKernel aus\\
% % TODO: siehe gVisor Doku und Whitepapers\\

% \subsection{AWS Firecracker}
% -- Benutzt KVM (Kernel-based Virtaul Machine, ähnlich sVMs)\\
% % TODO: https://assets.amazon.science/96/c6/302e527240a3b1f86c86c3e8fc3d/firecracker-lightweight-virtualization-for-serverless-applications.pdf

% \section{Eigenschaften serverloser Architekturen}
% -- Architekturdartstellung einer simplen Webanwendung, Frontend + Backend + Datenbank
% -- Vier eigenschaften des Serverless Computing bei jedem der Services deutlich machen
% -- Serverless sieht vor soviel wie möglich die Dienste der Cloud-Provider zuverwenden